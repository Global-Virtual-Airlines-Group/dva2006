#!/bin/bash
# ServInfo download script
# (c) 2006, 2009 Global Virtual Airlines Group. All Rights Reserved.

# Set the file to download to
if [ -z "$2" ]; then
 echo "servinfo <network> <path> [verbose] ..."
 exit 1
fi

# Turn on verbose operation if requested
QuietOpt=""
if [ -z "$3" ]; then
 QuietOpt="-q"
fi

# Get the status URL
if [ "IVAO" == "$1" ]; then
 StatusURL="http://www.ivao.aero/whazzup/status.txt"
 network="ivao"
elif [ "INTVAS" == "$1" ]; then
 StatusURL="http://www.intvas.net/whazzup/status.txt"
 network="intvas"
else
 StatusURL="http://usa-s1.vatsim.net/data/status.txt"
 network="vatsim"
fi

StatusFileField=$(echo -n "$StatusURL" | awk -F / '{print NF}')
StatusFile=$(echo -n "$StatusURL" | cut -d / -f $StatusFileField)

# Check if we're already downloading or reading
if [ -f "/tmp/$network.isactive" ]; then
 echo "$network data is busy!"
 sleep 1.5
 if [ -f "/tmp/$network.isactive" ]; then
  echo "Already downloading $network data!"
  exit 2
 else
  echo active > /tmp/$network.isactive
 fi
else
 echo active > /tmp/$network.isactive
fi

# Get the status file and active URLs
mkdir /tmp/$network
cd /tmp/$network
InfoTries=3
if [ -f "$2/$network.status" ]; then
 cp -f $2/$network.status /tmp/$network/$StatusFile
 touch -r $2/$network.status /tmp/$network/$StatusFile
 InfoTries=1
fi
wget $StatusURL -N --timeout=10 --tries=$InfoTries $QuietOpt
if [ -f "/tmp/$network/$StatusFile" ]; then
 cp -f /tmp/$network/$StatusFile $2/$network.status
 touch -r /tmp/$network/$StatusFile $2/$network.status
else
 echo "Invalid $network status data!"
fi

# Parse status file
cat $2/$network.status | grep url0= | grep -v ";url0=" | grep -v "gzurl" > /tmp/$network/active
cut -d = -f 2 /tmp/$network/active > /tmp/$network/urls

# Generate a random URL to load
UpperBound=$(cat /tmp/$network/urls | wc -l)
RandomLine=$((1 + ($UpperBound * $RANDOM) / (32767 + 1) ))

# Use sed to grab the random line and get rid of the trailing newline
MyURL=$(sed -n "$RandomLine{p;q;}" "/tmp/$network/urls")
URLSize=$(echo -n "$MyURL" | wc -c | sed "s/ //g")
URLSize=`expr $URLSize "-" 1`
MyURL=$(echo -n "$MyURL" | cut -b 0-${URLSize})
FileField=$(echo -n "$MyURL" | awk -F / '{print NF}')
InfoFile=$(echo -n "$MyURL" | cut -d / -f $FileField)

# Get the info file
LastMod=1
if [ -f "$2/$network.info" ]; then
 cp $2/$network.info /tmp/$network/$InfoFile
 touch -r $2/$network.info /tmp/$network/$InfoFile
 LastMod=$(stat -c %Y /tmp/$network/$InfoFile)
fi
wget $MyURL -N --timeout=10 --tries=5 $QuietOpt
if [ -f "/tmp/$network/$InfoFile" ]; then
 LastModDL=$(stat -c %Y /tmp/$network/$InfoFile)
 if [ "$LastMod" -ge "$LastModDL" ]; then
  echo "Downloaded file is same/older!"
 else
  cp /tmp/$network/$InfoFile $2/$network.info
  touch -r /tmp/$network/$InfoFile $2/$network.info
 fi 
else
 echo "Invalid $network traffic data!"
fi

# Clean up temp files
cd /tmp
rm -r /tmp/$network
rm $network.isactive
exit 0
