#!/bin/bash
# ServInfo download script
# (c) 2006 Global Virtual Airlines Group. All Rights Reserved.

# Set the file to download to
if [ -z "$2" ]; then
 echo "servinfo <network> <path> ..."
 exit 1
fi

# Get the status URL
if [ "IVAO" == "$1" ]; then
 StatusURL="http://www.ivao.aero/whazzup/status.txt"
 network="ivao"
elif [ "INTVAS" == "$1" ]; then
 StatusURL="http://www.intvas.net/whazzup/status.txt"
 network="intvas"
else
 StatusURL="http://usa-s1.vatsim.net/data/status.txt"
 network="vatsim"
fi

# Check if we're already downloading
if [ -f "/tmp/$network.isactive" ]; then
 echo "Already downloading $network data!"
 exit 2
else
 echo active > /tmp/$network.isactive
fi

# Get the status file and active URLs
wget $StatusURL -q -N --timeout=15 --tries=3 -O $2/$network.status.tmp
if [ -s "$2/$network.status.tmp" ]; then
 mv -f $2/$network.status.tmp $2/$network.status
else
 echo "Invalid $network status data!"
 rm $2/$network.status.tmp
fi

# Parse status file
cat $2/$network.status | grep url0= | grep -v ";url0=" | grep -v "gzurl" > /tmp/$network.active
cut -d "=" -f 2 /tmp/$network.active > /tmp/$network.urls

# Generate a random URL to load
UpperBound=$(cat /tmp/$network.urls | wc -l)
RandomLine=$((1 + ($UpperBound * $RANDOM) / (32767 + 1) ))

# Use sed to grab the random line and get rid of the trailing newline
MyURL=$(sed -n "$RandomLine{p;q;}" "/tmp/$network.urls")
URLSize=$(echo -n "$MyURL" | wc -c | sed "s/ //g")
URLSize=`expr $URLSize "-" 1`
MyURL=$(echo -n "$MyURL" | cut -b 0-${URLSize})

# Clean up temp files
rm /tmp/$network.active
rm /tmp/$network.urls

# Get the info file
wget $MyURL -N --timeout=15 --tries=3 -q -O $2/$network.info.tmp
if [ -s "$2/$network.info.tmp" ]; then
 mv -f $2/$network.info.tmp $2/$network.info
else
 echo "Invalid $network traffic data!"
 rm $2/$network.info.tmp
fi

rm /tmp/$network.isactive
exit 0
