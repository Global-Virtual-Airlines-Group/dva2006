#!/bin/bash
# ServInfo download script
# (c) 2006, 2009, 2010, 2012, 2015, 2019 Global Virtual Airlines Group. All Rights Reserved.

function log {
 logTime=$(date +'%m/%d/%Y %H:%M:%S')
 echo "$logTime $1"
}

# Set the file to download to
if [ -z "$2" ]; then
 echo "servinfo <network> <path> [verbose] ..."
 exit 1
fi

# Turn on verbose operation if requested
QuietOpt=""
if [ -z "$3" ]; then
 QuietOpt="-q"
fi

# Get the status URL
TrimCount=1
if [ "IVAO" == "$1" ]; then
 StatusURL="https://www.ivao.aero/whazzup/status.txt"
 network="ivao"
else
 StatusURL="https://status.vatsim.net/status.txt"
 network="vatsim"
fi

StatusFileField=$(echo -n "$StatusURL" | awk -F / '{print NF}')
StatusFile=$(echo -n "$StatusURL" | cut -d / -f $StatusFileField)

# Check if we're already downloading or reading
if [ -f "/tmp/$network.isactive" ]; then
 CurrentDate=$(date +%s)
 FlagDate=$(stat -c "%Y" /tmp/$network.isactive)
 FlagAge=$(($CurrentDate - $FlagDate))

 log "$network data is busy! ($FlagAge seconds)"
 if [ "$FlagAge" -ge 120 ]; then
  rm /tmp/$network.isactive
  rm -rf /tmp/$network
  log "Clearing stuck $network download"
 else
  sleep 2.5
 fi

 if [ -f "/tmp/$network.isactive" ]; then
  log "Already downloading $network data!"
  exit 2
 else
  echo active > /tmp/$network.isactive
 fi
else
 echo active > /tmp/$network.isactive
fi

# Get the status file and active URLs
mkdir /tmp/$network
cd /tmp/$network
InfoTries=3
if [ -f "$2/$network.status" ]; then
 cp -f $2/$network.status /tmp/$network/$StatusFile
 touch -r $2/$network.status /tmp/$network/$StatusFile
 InfoTries=1
fi
wget $StatusURL -N --timeout=10 --tries=$InfoTries $QuietOpt
if [ -f "/tmp/$network/$StatusFile" ]; then
 cp -f /tmp/$network/$StatusFile $2/$network.status
 touch -r /tmp/$network/$StatusFile $2/$network.status
else
 log "Invalid $network status data!"
fi

# Parse status file
cat $2/$network.status | grep url0= | grep -v ";url0=" | grep -v "gzurl" > /tmp/$network/active
cut -d = -f 2 /tmp/$network/active > /tmp/$network/urls

# Generate a random URL to load
UpperBound=$(cat /tmp/$network/urls | wc -l)
RandomLine=$((1 + ($UpperBound * $RANDOM) / (32767 + 1) ))

# Use sed to grab the random line and get rid of the trailing newline
MyURL=$(sed -n "$RandomLine{p;q;}" "/tmp/$network/urls")
URLSize=$(echo -n "$MyURL" | wc -c | sed "s/ //g")
MyURL=$(echo -n "$MyURL" | cut -b 1-${URLSize} | tr -d "\r")
FileField=$(echo -n "$MyURL" | awk -F / '{print NF}')
InfoFile=$(echo -n "$MyURL" | cut -d / -f $FileField)

# Get the info file
LastMod=1
if [ -f "$2/$network.info" ]; then
 cp $2/$network.info /tmp/$network/$InfoFile
 touch -r $2/$network.info /tmp/$network/$InfoFile
 LastMod=$(stat -c %Y /tmp/$network/$InfoFile)
fi
wget $MyURL -N --timeout=10 --tries=5 $QuietOpt
if [ -f "/tmp/$network/$InfoFile" ]; then
 LastModDL=$(stat -c %Y /tmp/$network/$InfoFile)
 if [ "$LastMod" -ge "$LastModDL" ]; then
  log "Downloaded file is same/older!"
 else
  cp /tmp/$network/$InfoFile $2/$network.info
  touch -r /tmp/$network/$InfoFile $2/$network.info
  ValidTime=$(grep "UPDATE = " $2/$network.info | cut -d' ' -f 3)
  wget -O /dev/null -q --timeout=5 --tries=3 "https://www.deltava.org/networkpull.ws?net=$network&d=$ValidTime"
 fi 
else
 log "Invalid $network traffic data!"
fi

# Clean up temp files
cd /tmp
rm -r /tmp/$network
rm $network.isactive
exit 0
